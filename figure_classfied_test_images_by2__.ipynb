{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import tarfile\n",
    "import urllib\n",
    "from scipy import ndimage\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "import cPickle as pickle\n",
    "import tensorflow as tf\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "image_size = 64  # Pixel width and height.\n",
    "pixel_depth = 255.0  # Number of levels per pixel.\n",
    "num_labels = 2\n",
    "num_channels = 3 # grayscale\n",
    "\n",
    "testFolders = ['/Users/meicg/Documents/MATLAB/label_64_1'];\n",
    "originalFolder = ['/Users/meicg/Documents/MATLAB/label_1']\n",
    "classifyFolders = ['/Users/meicg/Documents/MATLAB/auto_classify_0',\n",
    "                   '/Users/meicg/Documents/MATLAB/auto_classify_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/meicg/Documents/MATLAB/label_64_1\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 2] No such file or directory: '/Users/meicg/Documents/MATLAB/label_64_1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-a2e98c7bb332>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mtestDataSet\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloadTestImages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestFolders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m7000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-a2e98c7bb332>\u001b[0m in \u001b[0;36mloadTestImages\u001b[1;34m(data_folders, min_num_images, max_num_images)\u001b[0m\n\u001b[0;32m      5\u001b[0m   \u001b[1;32mfor\u001b[0m \u001b[0mfolder\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_folders\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mprint\u001b[0m \u001b[0mfolder\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[1;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m       \u001b[0mimage_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 2] No such file or directory: '/Users/meicg/Documents/MATLAB/label_64_1'"
     ]
    }
   ],
   "source": [
    "def loadTestImages(data_folders,min_num_images, max_num_images):\n",
    "  dataset = np.ndarray(\n",
    "    shape=(max_num_images, image_size, image_size, num_channels), dtype=np.float32)\n",
    "  image_index = 0\n",
    "  for folder in data_folders:\n",
    "    print folder\n",
    "    for image in os.listdir(folder):\n",
    "      image_file = os.path.join(folder, image)\n",
    "      try:\n",
    "        image_data = (ndimage.imread(image_file).astype(float) -\n",
    "                      pixel_depth / 2) / pixel_depth\n",
    "        if image_data.shape != (image_size, image_size, num_channels):\n",
    "          raise Exception('Unexpected image shape: %s' % str(image_data.shape))\n",
    "        dataset[image_index, :, :, :] = image_data\n",
    "        image_index += 1\n",
    "      except IOError as e:\n",
    "        print 'Could not read:', image_file, ':', e, '- it\\'s ok, skipping.'\n",
    "  num_images = image_index\n",
    "  dataset = dataset[0:num_images, :, :, :]\n",
    "  label_result = np.ndarray(shape=(num_images, num_labels ), dtype=np.float32)\n",
    "  print 'Full dataset tensor:', dataset.shape\n",
    "  print 'Mean:', np.mean(dataset)\n",
    "  print 'Standard deviation:', np.std(dataset)\n",
    "  return dataset,label_result \n",
    "\n",
    "testDataSet,label_result = loadTestImages(testFolders, 6000, 7000)\n",
    "\n",
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#batch_size = 128\n",
    "calculate_image_per_times = 1\n",
    "patch_size = 5\n",
    "depth = 16\n",
    "num_hidden = 512\n",
    "#lamada = 0.02\n",
    "graph = tf.Graph()\n",
    "\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data.\n",
    "  #tf_train_dataset = tf.placeholder(\n",
    "  #  tf.float32, shape=(batch_size, image_size, image_size, num_channels))\n",
    "  #tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  #tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  #tf_test_dataset = tf.constant(test_dataset)\n",
    "  tf_classify_dataset = tf.placeholder(\n",
    "    tf.float32, shape=(calculate_image_per_times, image_size, image_size, num_channels))\n",
    "  \n",
    "  # Variables.\n",
    "  conv1_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, num_channels, depth], stddev=0.1))\n",
    "  conv1_biases = tf.Variable(tf.zeros([depth]))\n",
    "  conv2_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, depth, depth*2], stddev=0.1))\n",
    "  conv2_biases = tf.Variable(tf.constant(0.0, shape=[depth*2]))\n",
    "  conv3_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, depth*2, depth*4], stddev=0.1))\n",
    "  conv3_biases = tf.Variable(tf.constant(0.0, shape=[depth*4]))\n",
    "  conv4_weights = tf.Variable(tf.truncated_normal(\n",
    "      [patch_size, patch_size, depth*4, depth*8], stddev=0.1))\n",
    "  conv4_biases = tf.Variable(tf.constant(1.0, shape=[depth*8]))\n",
    "\n",
    "\n",
    "  full_weights = tf.Variable(tf.truncated_normal(\n",
    "      [image_size / 16 * image_size / 16 * depth*8, num_hidden], stddev=0.1))\n",
    "  full_biases = tf.Variable(tf.constant(0.0, shape=[num_hidden]))\n",
    "  softmax_weights = tf.Variable(tf.truncated_normal(\n",
    "      [num_hidden, num_labels], stddev=0.1))\n",
    "  softmax_biases = tf.Variable(tf.constant(0.0, shape=[num_labels]))\n",
    "\n",
    "  # Dropout.\n",
    "  keep_prob = tf.placeholder(\"float\")\n",
    "  \n",
    "  # Model.\n",
    "  def model(data):\n",
    "    conv_1 = tf.nn.conv2d(data, conv1_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    relu_1 = tf.nn.relu(conv_1 + conv1_biases)\n",
    "    max_pool_1 = tf.nn.max_pool(relu_1, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1],padding = 'SAME')\n",
    "    \n",
    "    conv_2 = tf.nn.conv2d(max_pool_1, conv2_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    relu_2 = tf.nn.relu(conv_2 + conv2_biases)\n",
    "    max_pool_2 = tf.nn.max_pool(relu_2, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1],padding = 'SAME')\n",
    "    \n",
    "    conv_3 = tf.nn.conv2d(max_pool_2, conv3_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    relu_3 = tf.nn.relu(conv_3 + conv3_biases)\n",
    "    max_pool_3 = tf.nn.max_pool(relu_3, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1],padding = 'SAME')\n",
    "    \n",
    "    conv_4 = tf.nn.conv2d(max_pool_3, conv4_weights, [1, 1, 1, 1], padding='SAME')\n",
    "    relu_4 = tf.nn.relu(conv_4 + conv4_biases)\n",
    "    max_pool_4 = tf.nn.max_pool(relu_4, ksize = [1, 2, 2, 1], strides = [1, 2, 2, 1],padding = 'SAME')\n",
    "    \n",
    "    shape = max_pool_4.get_shape().as_list()\n",
    "    reshape = tf.reshape(max_pool_4, [shape[0], shape[1] * shape[2] * shape[3]])\n",
    "    full_layer = tf.nn.relu(tf.matmul(reshape, full_weights) + full_biases)\n",
    "    softmax_layer = tf.nn.dropout(full_layer, keep_prob)\n",
    "    return tf.matmul(softmax_layer, softmax_weights) + softmax_biases\n",
    "  \n",
    "  classify_prediction = tf.nn.softmax(model(tf_classify_dataset))\n",
    "  saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_loop = math.ceil(testDataSet.shape[0]/1.0/calculate_image_per_times)\n",
    "with tf.Session(graph = graph) as session:\n",
    "    tf.initialize_all_variables().run()\n",
    "    saver.restore(session,'conv_layer4_param9-4000')\n",
    "    for step in xrange(int(num_loop)):\n",
    "        start = step * calculate_image_per_times\n",
    "        end = (step + 1) * calculate_image_per_times \n",
    "        subset = testDataSet[start:end , :, :, :]\n",
    "        feed_dict = {tf_classify_dataset : subset ,keep_prob : 1}\n",
    "        label_result[start:end] = session.run(classify_prediction, feed_dict = feed_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.18602404  0.81397593]\n",
      "accuracy =  0.864197530864\n"
     ]
    }
   ],
   "source": [
    "print label_result[6000]\n",
    "count = 0\n",
    "for step in xrange(int(num_loop)):\n",
    "    if label_result[step, 0] > label_result[step, 1] :\n",
    "        #print step \n",
    "        count += 1\n",
    "accuracy = 1- count /num_loop\n",
    "print \"accuracy = \",accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/meicg/Documents/MATLAB/label_64_1']\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "#testFolders = ['/Users/meicg/Documents/MATLAB/label_64_1'];\n",
    "#originalFolder = ['/Users/meicg/Documents/MATLAB/label_1']\n",
    "#classifyFolders = ['/Users/meicg/Documents/MATLAB/auto_classify_0',\n",
    "#                   '/Users/meicg/Documents/MATLAB/auto_classify_1']\n",
    "def classifyTestImages(small_data_folders, original_data_folder, classify_folders ):\n",
    "    print small_data_folders \n",
    "    flag = 0\n",
    "    for image in os.listdir(small_data_folders[0]):\n",
    "        image_file_origin  = os.path.join(original_data_folder[0], image)\n",
    "        image_file_destination_0 = os.path.join(classify_folders[0], image )\n",
    "        image_file_destination_1 = os.path.join(classify_folders[1], image )\n",
    "        if label_result[flag][0] >=0.5 :\n",
    "            shutil.copyfile(image_file_origin ,image_file_destination_0)\n",
    "        elif label_result[flag][1] >0.5 :\n",
    "            shutil.copyfile(image_file_origin ,image_file_destination_1)\n",
    "        flag += 1\n",
    "    return flag\n",
    "\n",
    "flag2 = classifyTestImages(testFolders, originalFolder,classifyFolders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'flag2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-0d8bc56fcd15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mflag2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'flag2' is not defined"
     ]
    }
   ],
   "source": [
    "print flag2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "im = Image.open('/Users/meicg/Documents/MATLAB/label_0/27411_3.JPG')\n",
    "out = im.resize((64,64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out.save('test.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
